#!/usr/bin/env python3

# Parse the output from "pgbench -i" initialization and return
# a list of the runtimes of each section with one-word keys.
# Requires a PostgreSQL 13 or later pgbench
#
# Sample input:
#   done in 17.24 s (drop tables 0.03 s, create tables 0.00 s, client-side generate 11.68 s, primary keys 5.52 s).
#   done in 1638.72 s (drop tables 0.01 s, create tables 0.04 s, server-side generate 759.36 s, vacuum 628.60 s, primary keys 250.71 s).
# Sample output (without and with vacuum step):
# {"done": ["17.24"], "drop": ["0.03"], "create": ["0.00"], "clientside": ["11.68"], "primary": ["5.52"]}
# {"done": ["1638.72"], "drop": ["0.01"], "create": ["0.04"], "serverside": ["759.36"], "vacuum": ["628.60"], "primary": ["250.71"]}
import string
import re
import json

def parse_init_timing(filepath):
    out = {}
    with open(filepath, 'r') as f:
        line = f.readline()
        while line:
            if line.startswith('done'):
                # Standardize all delimiter punctuation into " s, "
                l=line.replace(" s (" , " s, ")
                l=l.replace(" s)" , " s, ")
                keys=l.split(" s,")
                for k in keys:
                    text=k.translate(str.maketrans('', '', string.punctuation)).lstrip()
                    try:
                        text=text.split(maxsplit=1)[0]
                        out[text]=re.findall(r'\d+.\d+$', k)[0]
                    except:
                        pass
            line = f.readline()
    return out

if __name__ == '__main__':
    filepath = 'results.txt'
    d = parse_init_timing(filepath)
    print(json.dumps(d))
